{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the HuggingFace repository and local path\n",
    "ct_filename = \"ct.nii.gz\"\n",
    "pancreas_segmentations_filename = \"segmentations/pancreas.nii.gz\"\n",
    "\n",
    "data_folder = \"./data\"\n",
    "encoded_images_dir = os.path.join(data_folder, \"encoded_imgs\")\n",
    "\n",
    "os.path.join(encoded_images_dir, 'enc_healthy_cubes.pkl')\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(encoded_images_dir, 'enc_healthy_cubes.pkl'), 'rb') as f:\n",
    "    enc_healthy_cubes = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(encoded_images_dir, 'enc_pancreatic_tumor_cubes.pkl'), 'rb') as f:\n",
    "    enc_pancreatic_tumor_cubes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_healthy_cubes.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfortunately some of the CTs have less than 10 samples bcs. they ended up being out of range\n",
    "\n",
    "- [ ] TODO Reduce to min. no. samples of all CTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def process_and_stack_tensors(enc_pancreatic_tumor_cubes):\n",
    "    \"\"\"\n",
    "    Process the tensors in the dictionary:\n",
    "    1. Stack the tensors, ignoring empty lists.\n",
    "    2. Take tensors with at least 5 entries along the first dimension.\n",
    "    3. Threshold them to 5 entries, dropping those with fewer than 5 entries.\n",
    "    4. Stack all the processed tensors along a new axis.\n",
    "\n",
    "    Parameters:\n",
    "    enc_pancreatic_tumor_cubes (dict): The input dictionary with lists of tensors.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: A tensor with all the processed tensors stacked along a new axis.\n",
    "    \"\"\"\n",
    "    # Stack the tensors, ignoring empty lists\n",
    "    stacked_inner_lists = [torch.stack(inner_list).squeeze(1) for inner_list in enc_pancreatic_tumor_cubes.values() if inner_list]\n",
    "\n",
    "    # Filter and reduce the tensors to have exactly 5 entries along the first dimension\n",
    "    filtered_and_reduced_tensors = [tensor[:5] for tensor in stacked_inner_lists if tensor.shape[0] >= 5]\n",
    "\n",
    "    # Stack all the processed tensors along a new axis\n",
    "    if filtered_and_reduced_tensors:\n",
    "        final_tensor = torch.stack(filtered_and_reduced_tensors)\n",
    "    else:\n",
    "        final_tensor = torch.tensor([])  # Return an empty tensor if no tensors meet the criteria\n",
    "\n",
    "    return final_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 5, 8, 24, 24, 24])\n",
      "torch.Size([42, 5, 8, 24, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "enc_pancreatic_tensors = process_and_stack_tensors(enc_pancreatic_tumor_cubes)\n",
    "enc_healthy_tensors = process_and_stack_tensors(enc_healthy_cubes)\n",
    "\n",
    "print(enc_pancreatic_tensors.shape)\n",
    "print(enc_healthy_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 5, 8, 24, 24, 24])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor = torch.cat([enc_healthy_tensors, enc_pancreatic_tensors], dim=0)\n",
    "final_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_labels = torch.zeros(enc_healthy_tensors.shape[0])\n",
    "pancreatic_labels = torch.ones(enc_pancreatic_tensors.shape[0])\n",
    "\n",
    "final_labels = torch.cat([healthy_labels, pancreatic_labels], dim=0)\n",
    "final_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = final_tensor\n",
    "labels = final_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply scaling and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_scale_features(features):\n",
    "    \"\"\"\n",
    "    Flatten and standardize the features.\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Original features of shape (n_samples, ...).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Flattened and standardized features of shape (n_samples, n_features_flat).\n",
    "    \"\"\"\n",
    "    n_samples = features.shape[0]\n",
    "    flattened_features = features.reshape(n_samples, -1)\n",
    "    scaler = StandardScaler()\n",
    "    flattened_features_std = scaler.fit_transform(flattened_features)\n",
    "    return flattened_features_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'features' is your data of shape (n_samples, 8, 24, 24, 24)\n",
    "# and 'labels' contains the labels (0 for healthy, 1 for unhealthy)\n",
    "# Load or generate your 'features' and 'labels' here\n",
    "\n",
    "# Flatten and scale features\n",
    "flattened_features_std = flatten_and_scale_features(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(features, n_components):\n",
    "    \"\"\"\n",
    "    Apply PCA to reduce dimensionality.\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Input features.\n",
    "        n_components (int): Number of components to retain.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: PCA-transformed features.\n",
    "        float: Total explained variance ratio.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    features_pca = pca.fit_transform(features)\n",
    "    explained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "    return features_pca, explained_variance\n",
    "\n",
    "def apply_tsne(features, n_components, perplexity=30):\n",
    "    \"\"\"\n",
    "    Apply t-SNE to reduce dimensionality.\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Input features.\n",
    "        n_components (int): Target number of dimensions.\n",
    "        perplexity (float): Perplexity parameter for t-SNE.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: t-SNE-transformed features.\n",
    "    \"\"\"\n",
    "    tsne = TSNE(n_components=n_components, perplexity=perplexity, random_state=42)\n",
    "    features_tsne = tsne.fit_transform(features)\n",
    "    return features_tsne\n",
    "\n",
    "def apply_umap(features, n_components, n_neighbors=15, min_dist=0.1):\n",
    "    \"\"\"\n",
    "    Apply UMAP to reduce dimensionality.\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Input features.\n",
    "        n_components (int): Target number of dimensions.\n",
    "        n_neighbors (int): Number of neighbors for UMAP.\n",
    "        min_dist (float): Minimum distance parameter for UMAP.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: UMAP-transformed features.\n",
    "    \"\"\"\n",
    "    umap_reducer = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        random_state=42\n",
    "    )\n",
    "    features_umap = umap_reducer.fit_transform(features)\n",
    "    return features_umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_and_evaluate(features, method, n_clusters, **kwargs):\n",
    "    \"\"\"\n",
    "    Perform clustering and evaluate performance.\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Input features for clustering.\n",
    "        method (str): Clustering method ('kmeans', 'agglomerative', 'gmm').\n",
    "        n_clusters (int): Number of clusters.\n",
    "        **kwargs: Additional keyword arguments for clustering algorithms.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    if method == 'kmeans':\n",
    "        clustering = KMeans(n_clusters=n_clusters, random_state=42, **kwargs)\n",
    "        clusters = clustering.fit_predict(features)\n",
    "    elif method == 'agglomerative':\n",
    "        clustering = AgglomerativeClustering(n_clusters=n_clusters, **kwargs)\n",
    "        clusters = clustering.fit_predict(features)\n",
    "    elif method == 'gmm':\n",
    "        clustering = GaussianMixture(n_components=n_clusters, random_state=42, **kwargs)\n",
    "        clusters = clustering.fit_predict(features)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported clustering method: {method}\")\n",
    "\n",
    "    # Evaluate clustering performance\n",
    "    if len(set(clusters)) > 1 and len(set(clusters)) < len(features):\n",
    "        silhouette_avg = silhouette_score(features, clusters)\n",
    "        calinski_harabasz = calinski_harabasz_score(features, clusters)\n",
    "        davies_bouldin = davies_bouldin_score(features, clusters)\n",
    "    else:\n",
    "        silhouette_avg = calinski_harabasz = davies_bouldin = np.nan\n",
    "\n",
    "    evaluation = {\n",
    "        'Silhouette Score': silhouette_avg,\n",
    "        'Calinski-Harabasz Score': calinski_harabasz,\n",
    "        'Davies-Bouldin Score': davies_bouldin\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def evaluate_clustering(features, labels):\n",
    "    \"\"\"\n",
    "    Evaluate clustering performance across different dimensionality reduction and clustering methods.\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Original high-dimensional features.\n",
    "        labels (numpy.ndarray): True labels (if available, not used in clustering).\n",
    "\n",
    "    Returns:\n",
    "        dict: Nested dictionaries containing DataFrames of evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Define parameter ranges\n",
    "    n_components_list = list(range(2, 56, 5))  # From 2 to 55 in steps of 5\n",
    "    n_clusters_list = list(range(2, 8))        # From 2 to 7 in steps of 1\n",
    "\n",
    "    dim_reduction_methods = ['PCA', 't-SNE', 'UMAP']\n",
    "    clustering_methods = ['kmeans', 'agglomerative', 'gmm']\n",
    "\n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "\n",
    "    for dim_name in dim_reduction_methods:\n",
    "        print(f\"\\nDimensionality Reduction Method: {dim_name}\")\n",
    "\n",
    "        # Initialize a nested dictionary to store results\n",
    "        results[dim_name] = {}\n",
    "\n",
    "        for n_components in n_components_list:\n",
    "            if dim_name == 't-SNE' and n_components > 3:\n",
    "                continue\n",
    "\n",
    "            print(f\"  n_components = {n_components}\")\n",
    "\n",
    "            # Apply dimensionality reduction\n",
    "            if dim_name == 'PCA':\n",
    "                reduced_features, explained_variance = apply_pca(features, n_components)\n",
    "                print(f\"    Explained Variance Ratio: {explained_variance:.4f}\")\n",
    "            elif dim_name == 't-SNE':\n",
    "                # Adjust perplexity if necessary based on n_components and sample size\n",
    "                reduced_features = apply_tsne(features, n_components=n_components)\n",
    "            elif dim_name == 'UMAP':\n",
    "                reduced_features = apply_umap(features, n_components=n_components)\n",
    "\n",
    "            # Initialize DataFrame for this n_components\n",
    "            key = f\"n_components_{n_components}\"\n",
    "            results[dim_name][key] = pd.DataFrame(\n",
    "                index=n_clusters_list,\n",
    "                columns=clustering_methods\n",
    "            )\n",
    "\n",
    "            for n_clusters in n_clusters_list:\n",
    "                for method in clustering_methods:\n",
    "                    # Perform clustering and evaluation\n",
    "                    evaluation = cluster_and_evaluate(\n",
    "                        reduced_features,\n",
    "                        method=method,\n",
    "                        n_clusters=n_clusters\n",
    "                    )\n",
    "                    # Store Silhouette Score in the DataFrame\n",
    "                    results[dim_name][key].loc[n_clusters, method] = evaluation['Silhouette Score']\n",
    "\n",
    "        print(\"  Evaluation complete.\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation ðŸ§ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensionality Reduction Method: PCA\n",
      "  n_components = 2\n",
      "    Explained Variance Ratio: 0.0840\n",
      "  n_components = 7\n",
      "    Explained Variance Ratio: 0.2058\n",
      "  n_components = 12\n",
      "    Explained Variance Ratio: 0.3135\n",
      "  n_components = 17\n",
      "    Explained Variance Ratio: 0.4137\n",
      "  n_components = 22\n",
      "    Explained Variance Ratio: 0.5102\n",
      "  n_components = 27\n",
      "    Explained Variance Ratio: 0.6004\n",
      "  n_components = 32\n",
      "    Explained Variance Ratio: 0.6866\n",
      "  n_components = 37\n",
      "    Explained Variance Ratio: 0.7697\n",
      "  n_components = 42\n",
      "    Explained Variance Ratio: 0.8466\n",
      "  n_components = 47\n",
      "    Explained Variance Ratio: 0.9179\n",
      "  n_components = 52\n",
      "    Explained Variance Ratio: 0.9793\n",
      "  Evaluation complete.\n",
      "\n",
      "Dimensionality Reduction Method: t-SNE\n",
      "  n_components = 2\n",
      "  Evaluation complete.\n",
      "\n",
      "Dimensionality Reduction Method: UMAP\n",
      "  n_components = 2\n",
      "  n_components = 7\n",
      "  n_components = 12\n",
      "  n_components = 17\n",
      "  n_components = 22\n",
      "  n_components = 27\n",
      "  n_components = 32\n",
      "  n_components = 37\n",
      "  n_components = 42\n",
      "  n_components = 47\n",
      "  n_components = 52\n",
      "  Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation\n",
    "results = evaluate_clustering(flattened_features_std, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for PCA:\n",
      "\n",
      "n_components = 2\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.415781      0.403015  0.412469\n",
      "3  0.471768      0.435367  0.471768\n",
      "4   0.42468      0.325491  0.207349\n",
      "5  0.372024      0.324841  0.187038\n",
      "6  0.369312      0.364407  0.176826\n",
      "7  0.378918      0.365611  0.268334\n",
      "\n",
      "\n",
      "n_components = 7\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.197427      0.178406  0.247093\n",
      "3  0.196978      0.186267  0.243406\n",
      "4  0.207885      0.210924  0.215972\n",
      "5  0.235804       0.23825  0.091066\n",
      "6  0.222924      0.260684  0.091944\n",
      "7  0.245807      0.264427  0.100665\n",
      "\n",
      "\n",
      "n_components = 12\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.128265      0.125084   0.18264\n",
      "3   0.13986      0.129365 -0.040489\n",
      "4  0.152924      0.130982 -0.005983\n",
      "5  0.138891      0.133962  0.000402\n",
      "6  0.143016      0.156038  0.006684\n",
      "7  0.147451      0.154797  0.009358\n",
      "\n",
      "\n",
      "n_components = 17\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.101461      0.135077  0.112626\n",
      "3    0.1046      0.135731  0.115402\n",
      "4  0.136785      0.136128  0.083596\n",
      "5  0.088546      0.116673  0.088546\n",
      "6   0.10559      0.122613  0.090307\n",
      "7  0.098124       0.10166  0.098124\n",
      "\n",
      "\n",
      "n_components = 22\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.086011       0.09898  0.081577\n",
      "3  0.080407      0.101154  0.080407\n",
      "4  0.086329        0.0992  0.086329\n",
      "5  0.117829      0.098654  0.060899\n",
      "6  0.065317      0.078688  0.065317\n",
      "7   0.13112      0.076356   0.06182\n",
      "\n",
      "\n",
      "n_components = 27\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.088016      0.098628  0.088016\n",
      "3  0.068502      0.100197  0.089277\n",
      "4   0.09013       0.09084   0.09013\n",
      "5  0.041764      0.093564  0.041764\n",
      "6  0.045498      0.094987  0.045498\n",
      "7  0.019935         0.098  0.019935\n",
      "\n",
      "\n",
      "n_components = 32\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.017781      0.082575  0.065162\n",
      "3  0.042034      0.083465  0.068359\n",
      "4  0.024402      0.082544  0.024402\n",
      "5  0.073782      0.082989  0.023745\n",
      "6   0.16545      0.084116  0.027008\n",
      "7  0.066387      0.036812 -0.003287\n",
      "\n",
      "\n",
      "n_components = 37\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.028258      0.065857  0.076995\n",
      "3  0.025288      0.066929  0.073227\n",
      "4  0.044697      0.066321  0.075719\n",
      "5  0.065465      0.045232  0.072934\n",
      "6  0.052688      0.033225  0.065929\n",
      "7  0.067985      0.035525  0.067985\n",
      "\n",
      "\n",
      "n_components = 42\n",
      "     kmeans agglomerative       gmm\n",
      "2 -0.009368       0.04191  0.042857\n",
      "3  0.018068      0.043242   0.04573\n",
      "4  0.048179       0.03259  0.048179\n",
      "5  0.101684      0.034521  0.050634\n",
      "6  0.029569      0.018238  0.029569\n",
      "7  0.031816      0.020319  0.031816\n",
      "\n",
      "\n",
      "n_components = 47\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.002438      0.041594  0.084654\n",
      "3  0.077819      0.042476  0.086079\n",
      "4  0.032704      0.037453  0.084813\n",
      "5  0.033795      0.038698  0.077905\n",
      "6  0.009575      0.037193  0.057304\n",
      "7  0.025998      0.027801  0.043343\n",
      "\n",
      "\n",
      "n_components = 52\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.009644      0.029569  0.058029\n",
      "3 -0.002366      0.030108  0.059611\n",
      "4  0.028814      0.025133  0.060782\n",
      "5  0.057053      0.026162  0.057053\n",
      "6  0.038161      0.024796  0.049372\n",
      "7  0.037982      0.017562  0.037982\n",
      "\n",
      "\n",
      "\n",
      "Results for t-SNE:\n",
      "\n",
      "n_components = 2\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.333609      0.286493  0.353892\n",
      "3  0.353235       0.29542  0.321182\n",
      "4  0.350649       0.28754  0.324073\n",
      "5  0.340967      0.303123  0.321626\n",
      "6  0.331515      0.315315  0.023125\n",
      "7   0.35002      0.329798  0.208338\n",
      "\n",
      "\n",
      "\n",
      "Results for UMAP:\n",
      "\n",
      "n_components = 2\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.392187      0.355898  0.392187\n",
      "3  0.393041      0.377982  0.393041\n",
      "4  0.342489      0.312147  0.342858\n",
      "5  0.314689      0.275356  0.329916\n",
      "6  0.314829       0.25788  0.262747\n",
      "7  0.303352      0.265273  0.144586\n",
      "\n",
      "\n",
      "n_components = 7\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.270217      0.219544  0.268809\n",
      "3  0.223316      0.219939   0.21913\n",
      "4  0.227542      0.207699  0.214941\n",
      "5   0.22297      0.211697  0.178856\n",
      "6   0.21317      0.198436  0.195344\n",
      "7  0.203148      0.201555  0.203148\n",
      "\n",
      "\n",
      "n_components = 12\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.253236       0.23366  0.235342\n",
      "3  0.250102      0.242059  0.185435\n",
      "4  0.226184      0.220598  0.170787\n",
      "5  0.183472       0.21496  0.181165\n",
      "6  0.200196      0.183797  0.141862\n",
      "7  0.167293       0.18599   0.10873\n",
      "\n",
      "\n",
      "n_components = 17\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.243623      0.204299  0.242057\n",
      "3  0.196844      0.214757  0.193481\n",
      "4  0.188305      0.186456  0.188305\n",
      "5  0.184691      0.177786  0.157667\n",
      "6  0.163817      0.151155   0.12018\n",
      "7  0.156329      0.160968    0.1284\n",
      "\n",
      "\n",
      "n_components = 22\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.24149       0.21014   0.24149\n",
      "3  0.237351      0.227375  0.197826\n",
      "4  0.206264      0.202077   0.19474\n",
      "5  0.170715       0.18525  0.186558\n",
      "6  0.204878       0.13368  0.147859\n",
      "7  0.168821      0.153692   0.16476\n",
      "\n",
      "\n",
      "n_components = 27\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.250534      0.216181  0.252021\n",
      "3   0.21125      0.233423  0.203768\n",
      "4  0.221084      0.205574  0.189924\n",
      "5  0.206518      0.206342  0.165824\n",
      "6  0.200921      0.200573   0.14531\n",
      "7   0.16075      0.158131  0.136073\n",
      "\n",
      "\n",
      "n_components = 32\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.252662      0.236272  0.248029\n",
      "3  0.243313      0.226582   0.20317\n",
      "4  0.229702      0.209934  0.171533\n",
      "5  0.167721      0.198228  0.162981\n",
      "6  0.187478      0.148821  0.155753\n",
      "7  0.185655      0.157428  0.169818\n",
      "\n",
      "\n",
      "n_components = 37\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.266444      0.240097  0.265702\n",
      "3  0.254769      0.244584  0.192099\n",
      "4  0.221092      0.206189  0.207686\n",
      "5  0.196398      0.163757   0.17583\n",
      "6  0.168288      0.168183  0.163623\n",
      "7  0.165844      0.179113  0.161069\n",
      "\n",
      "\n",
      "n_components = 42\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.252201      0.241236  0.247343\n",
      "3  0.250581      0.231664  0.195181\n",
      "4  0.219725      0.198211  0.209637\n",
      "5  0.200433      0.185144  0.191632\n",
      "6  0.168306      0.189071  0.148645\n",
      "7  0.155853      0.178322  0.155853\n",
      "\n",
      "\n",
      "n_components = 47\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.251986      0.222621   0.24858\n",
      "3  0.246647      0.242266  0.190145\n",
      "4  0.214047      0.201409  0.160783\n",
      "5  0.207761       0.21892  0.170639\n",
      "6  0.183652      0.192649  0.158247\n",
      "7  0.178018       0.20782  0.157862\n",
      "\n",
      "\n",
      "n_components = 52\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.25163       0.23362   0.25163\n",
      "3   0.24208      0.236792  0.202722\n",
      "4  0.223867      0.210106  0.218086\n",
      "5  0.201307      0.199843   0.18392\n",
      "6  0.178506      0.206642  0.178506\n",
      "7  0.172476      0.188018  0.156653\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the results for each dimensionality reduction method and n_components\n",
    "for dim_name, components_dict in results.items():\n",
    "    print(f\"\\nResults for {dim_name}:\\n\")\n",
    "    for n_components_key, df in components_dict.items():\n",
    "        print(f\"n_components = {n_components_key.split('_')[-1]}\")\n",
    "        print(df)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results ðŸ“Š\n",
    "\n",
    "PCA Optimal Number of Clusters:\n",
    "\tâ€¢\tFor n_components = 2, n_clusters = 3 yields the highest Silhouette Score (0.4718) with K-Means, suggesting that three clusters may better represent the underlying data structure in this reduced space.\n",
    "\n",
    "\n",
    "t-SNE Optimal Number of Clusters:\n",
    "\n",
    "â€¢\tK-Means with n_clusters = 3 gives a Silhouette Score of 0.3532, indicating that three clusters might be a good choice in t-SNE reduced space.\n",
    "\n",
    "UMAP:\n",
    "Optimal Number of Clusters:\n",
    "\tâ€¢\tWith n_components = 2, K-Means with n_clusters = 3 gives a Silhouette Score of 0.3930."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 6. StandardScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Assuming 'features' and 'labels' are your data and labels\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Flatten and scale features if not already done\u001b[39;00m\n\u001b[1;32m     19\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m---> 20\u001b[0m features_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:837\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:873\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \n\u001b[1;32m    843\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    872\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 873\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:953\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    959\u001b[0m     _assert_all_finite(\n\u001b[1;32m    960\u001b[0m         array,\n\u001b[1;32m    961\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    962\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    963\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    964\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 6. StandardScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assuming 'features' and 'labels' are your data and labels\n",
    "# Flatten and scale features if not already done\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nca(features, labels, n_components):\n",
    "    \"\"\"\n",
    "    Apply Neighborhood Components Analysis (NCA).\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Input features.\n",
    "        labels (numpy.ndarray): Class labels.\n",
    "        n_components (int): Number of dimensions to reduce to.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Transformed features.\n",
    "    \"\"\"\n",
    "    nca = NeighborhoodComponentsAnalysis(n_components=n_components, random_state=42)\n",
    "    nca.fit(features, labels)\n",
    "    return nca.transform(features)\n",
    "\n",
    "\n",
    "def apply_pls(features, labels, n_components):\n",
    "    \"\"\"\n",
    "    Apply Partial Least Squares (PLS) regression.\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Input features.\n",
    "        labels (numpy.ndarray): Class labels.\n",
    "        n_components (int): Number of components to keep.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Transformed features.\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    labels_binarized = lb.fit_transform(labels)\n",
    "    pls = PLSRegression(n_components=n_components)\n",
    "    pls.fit(features, labels_binarized)\n",
    "    return pls.transform(features)\n",
    "\n",
    "\n",
    "def apply_supervised_umap(features, labels, n_components, n_neighbors=15, min_dist=0.1):\n",
    "    \"\"\"\n",
    "    Apply Supervised UMAP.\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Input features.\n",
    "        labels (numpy.ndarray): Class labels.\n",
    "        n_components (int): Number of dimensions to reduce to.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Transformed features.\n",
    "    \"\"\"\n",
    "    reducer = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        random_state=42\n",
    "    )\n",
    "    return reducer.fit_transform(features, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_supervised_methods(features, labels):\n",
    "    \"\"\"\n",
    "    Evaluate clustering with supervised dimensionality reduction methods.\n",
    "\n",
    "    Parameters:\n",
    "        features (numpy.ndarray): Scaled features.\n",
    "        labels (numpy.ndarray): Class labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: Results for each method.\n",
    "    \"\"\"\n",
    "    n_components_list = list(range(2, min(features.shape[1], 56), 5))\n",
    "    n_clusters_list = list(range(2, 8))\n",
    "    dim_reduction_methods = ['NCA', 'PLS', 'Supervised UMAP']\n",
    "    clustering_methods = ['kmeans', 'agglomerative', 'gmm']\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for method in dim_reduction_methods:\n",
    "        print(f\"\\nDimensionality Reduction Method: {method}\")\n",
    "        results[method] = {}\n",
    "        for n_components in n_components_list:\n",
    "            print(f\"  n_components = {n_components}\")\n",
    "            if method == 'NCA':\n",
    "                try:\n",
    "                    transformed_features = apply_nca(features, labels, n_components)\n",
    "                except Exception as e:\n",
    "                    print(f\"    NCA failed at n_components={n_components}: {e}\")\n",
    "                    continue\n",
    "            elif method == 'PLS':\n",
    "                try:\n",
    "                    transformed_features = apply_pls(features, labels, n_components)\n",
    "                except Exception as e:\n",
    "                    print(f\"    PLS failed at n_components={n_components}: {e}\")\n",
    "                    continue\n",
    "            elif method == 'Supervised UMAP':\n",
    "                transformed_features = apply_supervised_umap(features, labels, n_components)\n",
    "            \n",
    "            results_key = f\"n_components_{n_components}\"\n",
    "            results[method][results_key] = pd.DataFrame(\n",
    "                index=n_clusters_list,\n",
    "                columns=clustering_methods\n",
    "            )\n",
    "            \n",
    "            for n_clusters in n_clusters_list:\n",
    "                for cluster_method in clustering_methods:\n",
    "                    evaluation = cluster_and_evaluate(\n",
    "                        transformed_features,\n",
    "                        method=cluster_method,\n",
    "                        n_clusters=n_clusters\n",
    "                    )\n",
    "                    # Store Silhouette Score\n",
    "                    results[method][results_key].loc[n_clusters, cluster_method] = evaluation['Silhouette Score']\n",
    "        print(\"  Evaluation complete.\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensionality Reduction Method: NCA\n",
      "  n_components = 2\n",
      "  n_components = 7\n",
      "  n_components = 12\n",
      "  n_components = 17\n",
      "  n_components = 22\n",
      "  n_components = 27\n",
      "  n_components = 32\n",
      "  n_components = 37\n",
      "  n_components = 42\n",
      "  n_components = 47\n",
      "  n_components = 52\n",
      "  Evaluation complete.\n",
      "\n",
      "Dimensionality Reduction Method: PLS\n",
      "  n_components = 2\n",
      "  n_components = 7\n",
      "  n_components = 12\n",
      "  n_components = 17\n",
      "  n_components = 22\n",
      "  n_components = 27\n",
      "  n_components = 32\n",
      "  n_components = 37\n",
      "  n_components = 42\n",
      "  n_components = 47\n",
      "  n_components = 52\n",
      "  Evaluation complete.\n",
      "\n",
      "Dimensionality Reduction Method: Supervised UMAP\n",
      "  n_components = 2\n",
      "  n_components = 7\n",
      "  n_components = 12\n",
      "  n_components = 17\n",
      "  n_components = 22\n",
      "  n_components = 27\n",
      "  n_components = 32\n",
      "  n_components = 37\n",
      "  n_components = 42\n",
      "  n_components = 47\n",
      "  n_components = 52\n",
      "  Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_supervised_methods(flattened_features_std, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for NCA:\n",
      "\n",
      "n_components_2\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.415781      0.403015  0.412469\n",
      "3  0.471768      0.435367  0.471768\n",
      "4   0.42468      0.325491  0.207349\n",
      "5  0.372024      0.324841  0.187038\n",
      "6  0.369312      0.364407  0.176826\n",
      "7  0.378918      0.365611  0.268334\n",
      "\n",
      "\n",
      "n_components_7\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.197427      0.178406  0.247093\n",
      "3  0.196978      0.186267  0.243406\n",
      "4  0.207885      0.210924  0.215972\n",
      "5  0.235804       0.23825  0.091066\n",
      "6  0.222924      0.260684  0.091944\n",
      "7  0.245807      0.264427  0.100665\n",
      "\n",
      "\n",
      "n_components_12\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.128265      0.125084   0.18264\n",
      "3   0.13986      0.129365 -0.040489\n",
      "4  0.152924      0.130982 -0.005983\n",
      "5  0.138891      0.133962  0.000402\n",
      "6  0.143016      0.156038  0.006684\n",
      "7  0.147451      0.154797  0.009358\n",
      "\n",
      "\n",
      "n_components_17\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.101461      0.135077  0.112626\n",
      "3    0.1046      0.135731  0.115402\n",
      "4  0.136785      0.136128  0.083596\n",
      "5  0.088546      0.116673  0.088546\n",
      "6   0.10559      0.122613  0.090307\n",
      "7  0.098124       0.10166  0.098124\n",
      "\n",
      "\n",
      "n_components_22\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.086011       0.09898  0.081577\n",
      "3  0.080407      0.101154  0.080407\n",
      "4  0.086329        0.0992  0.086329\n",
      "5  0.117829      0.098654  0.060899\n",
      "6  0.065317      0.078688  0.065317\n",
      "7   0.13112      0.076356   0.06182\n",
      "\n",
      "\n",
      "n_components_27\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.088016      0.098628  0.088016\n",
      "3  0.068502      0.100197  0.089277\n",
      "4   0.09013       0.09084   0.09013\n",
      "5  0.041764      0.093564  0.041764\n",
      "6  0.045498      0.094987  0.045498\n",
      "7  0.019935         0.098  0.019935\n",
      "\n",
      "\n",
      "n_components_32\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.017781      0.082575  0.065162\n",
      "3  0.042034      0.083465  0.068359\n",
      "4  0.024402      0.082544  0.024402\n",
      "5  0.073782      0.082989  0.023745\n",
      "6   0.16545      0.084116  0.027008\n",
      "7  0.066387      0.036812 -0.003287\n",
      "\n",
      "\n",
      "n_components_37\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.028258      0.065857  0.076995\n",
      "3  0.025288      0.066929  0.073227\n",
      "4  0.044697      0.066321  0.075719\n",
      "5  0.065465      0.045232  0.072934\n",
      "6  0.052688      0.033225  0.065929\n",
      "7  0.067985      0.035525  0.067985\n",
      "\n",
      "\n",
      "n_components_42\n",
      "     kmeans agglomerative       gmm\n",
      "2 -0.009368       0.04191  0.042857\n",
      "3  0.018068      0.043242   0.04573\n",
      "4  0.048179       0.03259  0.048179\n",
      "5  0.101684      0.034521  0.050634\n",
      "6  0.029569      0.018238  0.029569\n",
      "7  0.031816      0.020319  0.031816\n",
      "\n",
      "\n",
      "n_components_47\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.002438      0.041594  0.084654\n",
      "3  0.077819      0.042476  0.086079\n",
      "4  0.032704      0.037453  0.084813\n",
      "5  0.033795      0.038698  0.077905\n",
      "6  0.009575      0.037193  0.057304\n",
      "7  0.025998      0.027801  0.043343\n",
      "\n",
      "\n",
      "n_components_52\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.009644      0.029569  0.058029\n",
      "3 -0.002366      0.030108  0.059611\n",
      "4  0.028814      0.025133  0.060782\n",
      "5  0.057053      0.026162  0.057053\n",
      "6  0.038161      0.024796  0.049372\n",
      "7  0.037982      0.017562  0.037982\n",
      "\n",
      "\n",
      "\n",
      "Results for PLS:\n",
      "\n",
      "n_components_2\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.538995      0.538995  0.538995\n",
      "3  0.628407      0.618961  0.628407\n",
      "4  0.638562      0.637399  0.497189\n",
      "5  0.573671      0.612846  0.341211\n",
      "6  0.559454      0.552829  0.567857\n",
      "7  0.572942      0.563831  0.554178\n",
      "\n",
      "\n",
      "n_components_7\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.244748      0.244748  0.246453\n",
      "3  0.242264      0.218959  0.237269\n",
      "4  0.239486      0.217872  0.231352\n",
      "5  0.266893      0.226112   0.23558\n",
      "6  0.245014       0.24754  0.156688\n",
      "7   0.23083       0.26554  0.169631\n",
      "\n",
      "\n",
      "n_components_12\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.161255      0.147174  0.094181\n",
      "3  0.153997      0.151792  0.097217\n",
      "4  0.166343      0.153615  0.134927\n",
      "5  0.165698      0.153533  0.131253\n",
      "6  0.120094      0.169157   0.11591\n",
      "7  0.090594      0.175583  0.128086\n",
      "\n",
      "\n",
      "n_components_17\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.091238      0.080397  0.086913\n",
      "3  0.104504      0.094749  0.013848\n",
      "4  0.098937      0.097906  0.028624\n",
      "5  0.078142      0.110984  0.078142\n",
      "6  0.115443      0.111417  0.067519\n",
      "7   0.10948      0.114154  0.036881\n",
      "\n",
      "\n",
      "n_components_22\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.069413      0.050055  0.069386\n",
      "3   0.06756      0.057064  0.021023\n",
      "4  0.055473      0.060709  0.017323\n",
      "5  0.067133      0.063788  0.015706\n",
      "6  0.053673      0.068315  0.021568\n",
      "7   0.05901      0.070625 -0.005948\n",
      "\n",
      "\n",
      "n_components_27\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.06502      0.040635  0.014298\n",
      "3  0.063091      0.052666  0.034929\n",
      "4  0.058986      0.057633  0.034416\n",
      "5  0.022368      0.060377  0.031011\n",
      "6  0.039905      0.050853  0.014445\n",
      "7  0.036747      0.048366  0.024083\n",
      "\n",
      "\n",
      "n_components_32\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.06502      0.040635  0.014298\n",
      "3  0.063091      0.052666  0.034929\n",
      "4  0.058986      0.057633  0.034416\n",
      "5  0.022368      0.060377  0.031011\n",
      "6  0.039905      0.050853  0.014445\n",
      "7  0.036747      0.048366  0.024083\n",
      "\n",
      "\n",
      "n_components_37\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.06502      0.040635  0.014298\n",
      "3  0.063091      0.052666  0.034929\n",
      "4  0.058986      0.057633  0.034416\n",
      "5  0.022368      0.060377  0.031011\n",
      "6  0.039905      0.050853  0.014445\n",
      "7  0.036747      0.048366  0.024083\n",
      "\n",
      "\n",
      "n_components_42\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.06502      0.040635  0.014298\n",
      "3  0.063091      0.052666  0.034929\n",
      "4  0.058986      0.057633  0.034416\n",
      "5  0.022368      0.060377  0.031011\n",
      "6  0.039905      0.050853  0.014445\n",
      "7  0.036747      0.048366  0.024083\n",
      "\n",
      "\n",
      "n_components_47\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.06502      0.040635  0.014298\n",
      "3  0.063091      0.052666  0.034929\n",
      "4  0.058986      0.057633  0.034416\n",
      "5  0.022368      0.060377  0.031011\n",
      "6  0.039905      0.050853  0.014445\n",
      "7  0.036747      0.048366  0.024083\n",
      "\n",
      "\n",
      "n_components_52\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.06502      0.040635  0.014298\n",
      "3  0.063091      0.052666  0.034929\n",
      "4  0.058986      0.057633  0.034416\n",
      "5  0.022368      0.060377  0.031011\n",
      "6  0.039905      0.050853  0.014445\n",
      "7  0.036747      0.048366  0.024083\n",
      "\n",
      "\n",
      "\n",
      "Results for Supervised UMAP:\n",
      "\n",
      "n_components_2\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.938112      0.938112  0.938112\n",
      "3   0.50139      0.489448  0.491243\n",
      "4  0.512031      0.469079  0.483116\n",
      "5  0.475497      0.473635  0.471246\n",
      "6  0.461778      0.465434  0.426843\n",
      "7  0.486533      0.351255  0.428404\n",
      "\n",
      "\n",
      "n_components_7\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.921221      0.921221  0.921221\n",
      "3  0.386399      0.367767   0.35207\n",
      "4  0.345559        0.3168  0.327272\n",
      "5  0.227745      0.312386  0.209432\n",
      "6  0.218047      0.194535   0.20389\n",
      "7  0.203648      0.200982  0.202753\n",
      "\n",
      "\n",
      "n_components_12\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.939151      0.939151  0.939151\n",
      "3  0.384801      0.383708  0.384496\n",
      "4  0.335343      0.331051   0.26685\n",
      "5  0.210773      0.213415  0.213232\n",
      "6  0.193039      0.207387  0.203406\n",
      "7  0.201136      0.207951  0.204103\n",
      "\n",
      "\n",
      "n_components_17\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.959937      0.959937  0.959937\n",
      "3  0.387225      0.346031  0.386843\n",
      "4  0.349215      0.332179  0.259874\n",
      "5  0.199641      0.321786  0.199641\n",
      "6  0.195632      0.195339  0.182298\n",
      "7  0.188204      0.194259  0.188204\n",
      "\n",
      "\n",
      "n_components_22\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.944203      0.944203  0.944203\n",
      "3  0.398443       0.39032   0.39407\n",
      "4  0.351535      0.328604  0.354236\n",
      "5  0.223097      0.202982  0.331927\n",
      "6  0.220117      0.206085  0.322147\n",
      "7  0.192329      0.190575  0.300227\n",
      "\n",
      "\n",
      "n_components_27\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.948825      0.948825  0.948825\n",
      "3  0.399066      0.363293  0.399066\n",
      "4  0.293303      0.312057  0.293303\n",
      "5  0.230324      0.206287  0.197908\n",
      "6  0.200244      0.202123  0.193791\n",
      "7  0.202555      0.202595   0.19726\n",
      "\n",
      "\n",
      "n_components_32\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.91726       0.91726   0.91726\n",
      "3  0.387167      0.345841  0.382252\n",
      "4  0.331003      0.322499  0.331003\n",
      "5  0.319112      0.317694  0.318514\n",
      "6  0.305412      0.184373  0.302856\n",
      "7  0.157399      0.180748  0.280675\n",
      "\n",
      "\n",
      "n_components_37\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.954313      0.954313  0.954313\n",
      "3  0.391691      0.367678  0.385129\n",
      "4  0.276509      0.339793  0.272114\n",
      "5  0.248186      0.226806  0.206477\n",
      "6  0.202763      0.240208  0.202763\n",
      "7  0.208124      0.209488  0.208124\n",
      "\n",
      "\n",
      "n_components_42\n",
      "     kmeans agglomerative       gmm\n",
      "2   0.93732       0.93732   0.93732\n",
      "3   0.38348      0.374827  0.381582\n",
      "4   0.35114      0.323291  0.335133\n",
      "5  0.214353      0.209294  0.216603\n",
      "6   0.21531      0.202224  0.157295\n",
      "7  0.200334      0.201809   0.16027\n",
      "\n",
      "\n",
      "n_components_47\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.954311      0.954311  0.954311\n",
      "3  0.393089      0.381623  0.393089\n",
      "4  0.284945      0.273477  0.330611\n",
      "5  0.215736        0.2387  0.222475\n",
      "6  0.204366      0.227792  0.208413\n",
      "7  0.184656      0.240547  0.197668\n",
      "\n",
      "\n",
      "n_components_52\n",
      "     kmeans agglomerative       gmm\n",
      "2  0.945318      0.945318  0.945318\n",
      "3  0.390752      0.362295  0.386593\n",
      "4  0.349697      0.332092  0.349697\n",
      "5  0.332139      0.334707  0.336476\n",
      "6  0.194556      0.206122  0.298054\n",
      "7  0.184698      0.187158  0.304164\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method, n_components_dict in results.items():\n",
    "    print(f\"\\nResults for {method}:\\n\")\n",
    "    for n_components, df in n_components_dict.items():\n",
    "        print(f\"{n_components}\")\n",
    "        print(df)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Silhouette Scores, the best clustering result is:\n",
    "\n",
    "\tâ€¢\tDimensionality Reduction Method: Supervised UMAP\n",
    "\tâ€¢\tNumber of Components (n_components): 17\n",
    "\tâ€¢\tClustering Method: K-Means\n",
    "\tâ€¢\tNumber of Clusters (n_clusters): 2\n",
    "\tâ€¢\tSilhouette Score: 0.959937\n",
    "\n",
    "\n",
    "Saving that as a TSV for Projector.tensorflow.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assume 'features' and 'labels' are your data and labels\n",
    "# Flatten and scale features if not already done\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(flattened_features_std)\n",
    "\n",
    "# Apply Supervised UMAP with n_components = 17\n",
    "n_components = 17\n",
    "reducer = umap.UMAP(\n",
    "    n_components=n_components,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "embedding = reducer.fit_transform(features_scaled, y=labels)\n",
    "\n",
    "# Perform K-Means clustering with n_clusters = 2\n",
    "n_clusters = 2\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_assignments = kmeans.fit_predict(embedding)\n",
    "\n",
    "# Prepare data for TSV files\n",
    "# Create a DataFrame for the embedding\n",
    "embedding_df = pd.DataFrame(embedding)\n",
    "\n",
    "# Add cluster assignments and true labels\n",
    "embedding_df['Cluster'] = cluster_assignments\n",
    "embedding_df['Label'] = labels  # Ensure 'labels' is an array-like object\n",
    "\n",
    "# Save the embedding vectors (without Cluster and Label columns)\n",
    "embedding_df.drop(columns=['Cluster', 'Label']).to_csv('features.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Save the metadata (Cluster assignments and Labels)\n",
    "metadata_df = embedding_df[['Cluster', 'Label']]\n",
    "metadata_df.to_csv('metadata.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting better than Projector.Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for method, n_components_dict in results.items():\n",
    "    for n_components_key, df in n_components_dict.items():\n",
    "        n_components = n_components_key.split('_')[-1]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(df.astype(float), annot=True, fmt=\".3f\", cmap='viridis')\n",
    "        plt.title(f'{method} with n_components = {n_components}')\n",
    "        plt.xlabel('Clustering Method')\n",
    "        plt.ylabel('Number of Clusters')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
